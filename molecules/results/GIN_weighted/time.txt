3.173978805541992
2.9051520824432373
2.745737075805664
2.777604103088379
3.1000711917877197
2.815859079360962
2.867182970046997
2.8155100345611572
2.706367254257202
2.7844088077545166
2.797729969024658
2.6895270347595215
2.773827075958252
2.7000620365142822
2.741055965423584
2.8659818172454834
2.895094633102417
3.05074405670166
2.8240818977355957
2.861470937728882
3.028841972351074
3.325977087020874
3.260864019393921
3.284804105758667
3.0883421897888184
3.0743470191955566
3.043099880218506
3.379725217819214
3.620609998703003
3.1156399250030518
2.8859078884124756
3.0739340782165527
3.035703659057617
3.003270149230957
3.081264019012451
3.018630027770996
3.0159990787506104
3.0489790439605713
3.0604259967803955
3.047025203704834
3.091853141784668
3.071259021759033
3.141756772994995
3.022275924682617
3.167968988418579
3.135981798171997
3.0773792266845703
3.074629068374634
3.108881950378418
3.0797760486602783
3.1638529300689697
3.0579769611358643
3.0725581645965576
3.0498621463775635
3.069521188735962
3.235598087310791
3.0003738403320312
3.058661937713623
3.0347578525543213
3.0779640674591064
3.0842580795288086
3.0942230224609375
3.0980238914489746
3.1226601600646973
3.111737012863159
3.1185407638549805
3.09995698928833
3.1054341793060303
3.092042922973633
3.1139261722564697
3.0719997882843018
3.14245867729187
3.157589912414551
3.084506034851074
3.1265039443969727
3.0353729724884033
2.963643789291382
3.0283069610595703
3.0495920181274414
3.022139072418213
3.0229640007019043
3.1373958587646484
3.073106050491333
3.049833059310913
3.1452019214630127
2.994734048843384
3.0668039321899414
3.055562973022461
3.0615129470825195
3.0569779872894287
3.1099777221679688
3.0294549465179443
3.0266261100769043
3.115363121032715
3.058306932449341
3.146920919418335
3.0416886806488037
3.020787000656128
3.065455913543701
3.0904700756073
3.0866518020629883
3.0673131942749023
3.37650203704834
3.0385353565216064
3.202425956726074
2.9021670818328857
2.671980142593384
2.66133975982666
2.897768974304199
2.685778856277466
2.683042049407959
2.6941678524017334
2.813727855682373
3.1163790225982666
3.0959720611572266
2.758441925048828
2.7178938388824463
2.970338821411133
2.7846410274505615
2.7563018798828125
2.7957019805908203
2.717072010040283
2.7410638332366943
2.7653400897979736
2.722761869430542
2.7073049545288086
2.7921652793884277
2.981175184249878
2.907248020172119
2.8349499702453613
2.772918939590454
3.1069750785827637
3.1908888816833496
2.8984217643737793
2.8376948833465576
2.991770029067993
2.793123960494995
2.8278520107269287
2.70532488822937
2.7860050201416016
2.8235580921173096
2.7280237674713135
2.9551188945770264
2.6924829483032227
2.7826130390167236
2.875627040863037
2.697435140609741
2.709657907485962
2.7301621437072754
2.720896005630493
2.7668988704681396
2.7057671546936035
2.7452402114868164
2.704552173614502
2.7738497257232666
2.8075098991394043
2.877403974533081
2.9209389686584473
2.8358278274536133
3.072208881378174
2.9792370796203613
2.8238179683685303
2.9459290504455566
2.83585786819458
2.845889091491699
2.7741246223449707
2.8075037002563477
2.7814018726348877
2.77058482170105
2.8677897453308105
2.792771100997925
2.8932979106903076
2.9027271270751953
2.790847063064575
2.996664047241211
2.870526075363159
2.965254068374634
2.962460994720459
3.1075000762939453
2.9267561435699463
2.897869825363159
2.752316951751709
2.8564422130584717
2.8909361362457275
2.954864263534546
3.1924889087677
2.870143175125122
2.849081039428711
2.9319231510162354
2.8569209575653076
3.1452980041503906
3.001075029373169
3.279862880706787
2.806781053543091
2.7943432331085205
2.8502767086029053
2.851459264755249
2.79872727394104
2.8419580459594727
2.8461430072784424
2.8179099559783936
2.7684390544891357
2.9580438137054443
2.8857781887054443
2.8389599323272705
2.7576849460601807
2.7761342525482178
2.7650609016418457
2.7768571376800537
2.7287139892578125
2.860132932662964
2.8327388763427734
2.8313181400299072
2.878675937652588
2.843924045562744
2.7540721893310547
2.7803869247436523
2.7488410472869873
2.771516799926758
2.931969165802002
2.816323757171631
2.7667269706726074
2.7060799598693848
2.798980236053467
2.7225899696350098
2.779116153717041
2.8852310180664062
2.8212099075317383
2.866615056991577
2.766417980194092
2.83622407913208
2.89809513092041
2.8297929763793945
2.890815258026123
3.0972700119018555
2.9187769889831543
2.908715009689331
2.8705971240997314
2.9503729343414307
2.956415891647339
2.9003939628601074
2.863846778869629
2.833838939666748
2.8214049339294434
3.0891480445861816
2.952448844909668
3.0966720581054688
3.000839948654175
2.7969868183135986


Namespace(target=0, bs=128, hid_dim=100, path='Data_Molecules/QM7b', result_path='./results_QM7b/GIN_concat', node_feature_dim=100)
Data(edge_index=[2, 25], edge_attr=[25], y=[1, 1], f_d=[5, 100], f_o=[20, 100], f_star=[1, 100], num_nodes=5)
/opt/anaconda3/envs/eml/lib/python3.10/site-packages/torch_geometric/nn/models/mlp.py:102: UserWarning: Argument `batch_norm` is deprecated, please use `norm` to specify normalization layer.
  warnings.warn("Argument `batch_norm` is deprecated, "
  1%|▉                                                                                                 | 9/1000 [00:27<48:40,  2.95s/it]Epoch=10, LR=0.005000, Loss=210.6121, Val MAE=777.6516
  2%|█▊                                                                                               | 19/1000 [00:56<48:05,  2.94s/it]Epoch=20, LR=0.005000, Loss=41.9347, Val MAE=123.2178
  3%|██▊                                                                                              | 29/1000 [01:28<53:42,  3.32s/it]Epoch=30, LR=0.004000, Loss=35.9903, Val MAE=36.8043
  4%|███▊                                                                                             | 39/1000 [01:59<48:54,  3.05s/it]Epoch=40, LR=0.003200, Loss=29.0531, Val MAE=52.1501
  5%|████▊                                                                                            | 49/1000 [02:30<49:05,  3.10s/it]Epoch=50, LR=0.002048, Loss=26.7151, Val MAE=19.4068
  6%|█████▋                                                                                           | 59/1000 [03:01<49:30,  3.16s/it]Epoch=60, LR=0.001638, Loss=24.9988, Val MAE=15.9847
  7%|██████▋                                                                                          | 69/1000 [03:32<48:09,  3.10s/it]Epoch=70, LR=0.001311, Loss=24.6019, Val MAE=17.7710
  8%|███████▋                                                                                         | 79/1000 [04:03<47:11,  3.07s/it]Epoch=80, LR=0.001049, Loss=23.3465, Val MAE=22.1724
  9%|████████▋                                                                                        | 89/1000 [04:34<47:49,  3.15s/it]Epoch=90, LR=0.000839, Loss=21.8458, Val MAE=14.9404
 10%|█████████▌                                                                                       | 99/1000 [05:04<46:33,  3.10s/it]Epoch=100, LR=0.000671, Loss=20.4643, Val MAE=14.9658
 11%|██████████▍                                                                                     | 109/1000 [05:35<42:46,  2.88s/it]Epoch=110, LR=0.000537, Loss=22.5506, Val MAE=15.5962
 12%|███████████▍                                                                                    | 119/1000 [06:03<41:53,  2.85s/it]Epoch=120, LR=0.000429, Loss=20.2971, Val MAE=13.7733
 13%|████████████▍                                                                                   | 129/1000 [06:31<41:31,  2.86s/it]Epoch=130, LR=0.000344, Loss=22.6535, Val MAE=15.0335
 14%|█████████████▎                                                                                  | 139/1000 [07:00<40:34,  2.83s/it]Epoch=140, LR=0.000220, Loss=22.2734, Val MAE=11.8112
 15%|██████████████▎                                                                                 | 149/1000 [07:28<39:36,  2.79s/it]Epoch=150, LR=0.000220, Loss=20.9975, Val MAE=12.3703
 16%|███████████████▎                                                                                | 159/1000 [07:56<39:44,  2.84s/it]Epoch=160, LR=0.000176, Loss=21.6227, Val MAE=12.0939
 17%|████████████████▏                                                                               | 169/1000 [08:25<38:55,  2.81s/it]Epoch=170, LR=0.000113, Loss=19.3599, Val MAE=16.3279
 18%|█████████████████▏                                                                              | 179/1000 [08:54<40:45,  2.98s/it]Epoch=180, LR=0.000090, Loss=22.5482, Val MAE=11.5483
 19%|██████████████████▏                                                                             | 189/1000 [09:24<40:01,  2.96s/it]Epoch=190, LR=0.000058, Loss=20.4536, Val MAE=11.2352
 20%|███████████████████                                                                             | 199/1000 [09:53<38:22,  2.87s/it]Epoch=200, LR=0.000058, Loss=20.3679, Val MAE=16.2281
 21%|████████████████████                                                                            | 209/1000 [10:21<36:49,  2.79s/it]Epoch=210, LR=0.000037, Loss=20.3453, Val MAE=11.1025
 22%|█████████████████████                                                                           | 219/1000 [10:49<36:13,  2.78s/it]Epoch=220, LR=0.000024, Loss=21.1242, Val MAE=12.2463
 23%|█████████████████████▉                                                                          | 229/1000 [11:17<36:19,  2.83s/it]Epoch=230, LR=0.000019, Loss=21.4345, Val MAE=12.1595
 24%|██████████████████████▉                                                                         | 239/1000 [11:46<37:01,  2.92s/it]Epoch=240, LR=0.000012, Loss=19.0978, Val MAE=12.4386
 24%|███████████████████████▎                                                                        | 243/1000 [12:01<37:26,  2.97s/it]
[Fold] Best test MAE = 10.43953.723172664642334