4.178236961364746
3.5747220516204834
3.488316059112549
3.314028024673462
3.2594642639160156
3.221771001815796
3.2528817653656006
3.2586140632629395
3.2726261615753174
3.4707229137420654
3.6886088848114014
3.4740710258483887
3.452125310897827
3.4063687324523926
3.3576560020446777
3.283478021621704
3.342500686645508
3.5450198650360107
3.3947038650512695
3.360180139541626
3.460829973220825
3.449007034301758
3.366736888885498
3.3611907958984375
3.56636381149292
4.25338888168335
4.015625953674316
3.944681167602539
3.3116989135742188
3.2131471633911133
3.151218891143799
3.3504199981689453
3.167510747909546
3.122419834136963
3.2676808834075928
3.14176607131958
3.2239527702331543
3.145876884460449
3.149686098098755
3.1581130027770996
3.125614881515503
3.1476078033447266
3.242497205734253
3.2075610160827637
3.095745086669922
3.7434628009796143
3.8858120441436768
3.8334920406341553
3.5052120685577393
3.7260169982910156
3.3113961219787598
3.6373000144958496
4.795006036758423
3.9271419048309326
3.250455141067505
3.443983793258667
3.1903340816497803
3.1450891494750977
3.1189959049224854
3.125792980194092
3.1303470134735107
3.133713960647583
3.1236021518707275
3.2991039752960205
3.2425310611724854
3.4219729900360107
3.2892532348632812
3.1645901203155518
3.112846851348877
3.166940212249756
3.555176019668579
3.2603871822357178
3.7749249935150146
3.1437737941741943
3.099163055419922
3.156342029571533
3.397975206375122
3.320046901702881
3.2355411052703857
3.1587271690368652
3.2166848182678223
3.1236653327941895
3.1253440380096436
3.133521795272827
3.129239082336426
3.1561148166656494
3.329406976699829
3.2662861347198486
3.1901330947875977
3.5038862228393555
3.5467920303344727
3.463787078857422
3.7884953022003174
3.594442129135132
3.6190237998962402
3.829730749130249
3.3578438758850098
3.5194478034973145
3.7085816860198975
3.4655487537384033
3.5767810344696045
3.4303417205810547
3.5056111812591553
3.5524418354034424
3.4402577877044678
3.3685991764068604
3.262251138687134
3.3380448818206787
3.1998510360717773
3.4616079330444336
3.5685999393463135
3.526057004928589
3.603193759918213
3.6048238277435303
3.333608865737915
3.519418954849243
3.61860990524292
3.4713261127471924
3.4489147663116455
3.367553949356079
3.502380132675171
3.993891954421997
3.901350975036621
3.7746970653533936
4.014791965484619
3.231826066970825
3.2235000133514404
3.236379861831665
3.3336498737335205
3.364002227783203
3.3602170944213867
3.359454870223999
3.3621037006378174
3.3412818908691406
3.3591248989105225
3.3341429233551025
3.347490072250366
3.341002941131592
3.3470938205718994
3.3514559268951416
3.2447988986968994
3.1933679580688477
3.2429330348968506
3.2287118434906006
3.2225239276885986
3.2024729251861572
3.201072931289673
3.2076141834259033
3.412946939468384
3.2010738849639893
3.189545154571533
3.196873188018799
3.2000560760498047
3.225548028945923
3.1940579414367676
3.2118639945983887
3.355491876602173
3.213319778442383
3.1701269149780273
3.2787041664123535
3.1885759830474854
3.2147819995880127
3.2014667987823486
3.186086893081665
3.2373030185699463
3.2399587631225586
3.3789470195770264
3.485421657562256
3.4737632274627686
3.33135986328125
3.2501120567321777
3.2106268405914307
3.3848252296447754
3.8129751682281494
4.145165920257568
4.115274906158447
4.212849140167236
4.130290985107422
4.1387152671813965
4.199474096298218
4.178603172302246
4.295541048049927
4.096993923187256
4.649497747421265
4.101994276046753
3.2340617179870605
3.2485928535461426
3.2107560634613037
3.252330780029297
3.4251749515533447
3.4136581420898438
3.622169256210327
3.414459228515625
3.5312869548797607
4.240267038345337
4.01152777671814
3.5569589138031006
3.233786106109619
3.305417060852051
3.459113359451294
3.6155660152435303
3.8259987831115723
3.986943006515503
3.858788013458252
3.9842469692230225
3.3775148391723633
3.4664392471313477
3.417153835296631
3.355412006378174
3.504563808441162
3.5688841342926025
3.3956191539764404
3.6226260662078857
3.9422760009765625
3.3046352863311768
3.5863590240478516
4.067264080047607
3.8894741535186768
3.6385793685913086
3.5016047954559326
3.523123025894165
3.8966872692108154
3.9563710689544678
4.026343822479248
3.9040870666503906
3.8107399940490723
3.540750026702881
3.6913862228393555
3.5196402072906494
3.3772149085998535
3.3741838932037354
3.95719313621521
3.5218539237976074
3.8472959995269775
3.279372215270996
3.339505910873413
3.2658638954162598
3.234818696975708
3.73551607131958
3.6083948612213135
3.4145429134368896
3.320953845977783
3.3319151401519775
3.2941460609436035
3.700434923171997


Data(edge_index=[2, 25], edge_attr=[25], y=[1, 1], f_d=[5, 100], f_o=[20, 100], f_star=[1, 100], num_nodes=5)
/opt/anaconda3/envs/eml/lib/python3.10/site-packages/torch_geometric/nn/models/mlp.py:102: UserWarning: Argument `batch_norm` is deprecated, please use `norm` to specify normalization layer.
  warnings.warn("Argument `batch_norm` is deprecated, "
  1%|▉                                                                                                 | 9/1000 [00:32<57:35,  3.49s/it]Epoch=10, LR=0.005000, Loss=231.6698, Val MAE=101.0170
  2%|█▊                                                                                               | 19/1000 [01:07<57:16,  3.50s/it]Epoch=20, LR=0.005000, Loss=34.8431, Val MAE=28.8201
  3%|██▊                                                                                            | 29/1000 [01:44<1:00:09,  3.72s/it]Epoch=30, LR=0.004000, Loss=27.4913, Val MAE=23.3025
  4%|███▊                                                                                             | 39/1000 [02:16<51:17,  3.20s/it]Epoch=40, LR=0.003200, Loss=30.3645, Val MAE=66.4541
  5%|████▊                                                                                            | 49/1000 [02:50<56:48,  3.58s/it]Epoch=50, LR=0.002560, Loss=27.2874, Val MAE=63.0869
  6%|█████▋                                                                                           | 59/1000 [03:26<51:59,  3.31s/it]Epoch=60, LR=0.001638, Loss=26.6795, Val MAE=18.0818
  7%|██████▋                                                                                          | 69/1000 [03:58<49:46,  3.21s/it]Epoch=70, LR=0.001049, Loss=24.1554, Val MAE=14.6593
  8%|███████▋                                                                                         | 79/1000 [04:31<51:19,  3.34s/it]Epoch=80, LR=0.000839, Loss=23.3022, Val MAE=38.5715
  9%|████████▋                                                                                        | 89/1000 [05:03<48:59,  3.23s/it]Epoch=90, LR=0.000839, Loss=20.3815, Val MAE=16.9730
 10%|█████████▌                                                                                       | 99/1000 [05:40<54:27,  3.63s/it]Epoch=100, LR=0.000537, Loss=22.8922, Val MAE=20.3219
 11%|██████████▍                                                                                     | 109/1000 [06:14<49:26,  3.33s/it]Epoch=110, LR=0.000344, Loss=22.8627, Val MAE=12.9644
 12%|███████████▍                                                                                    | 119/1000 [06:50<51:39,  3.52s/it]Epoch=120, LR=0.000344, Loss=21.4300, Val MAE=13.0164
 13%|████████████▍                                                                                   | 129/1000 [07:25<49:24,  3.40s/it]Epoch=130, LR=0.000220, Loss=21.9229, Val MAE=13.1446
 14%|█████████████▎                                                                                  | 139/1000 [07:59<48:02,  3.35s/it]Epoch=140, LR=0.000141, Loss=21.7675, Val MAE=13.2709
 15%|██████████████▎                                                                                 | 149/1000 [08:31<46:29,  3.28s/it]Epoch=150, LR=0.000113, Loss=20.8429, Val MAE=14.2960
 16%|███████████████▎                                                                                | 159/1000 [09:04<45:45,  3.26s/it]Epoch=160, LR=0.000072, Loss=23.1837, Val MAE=12.3910
 17%|████████████████▏                                                                               | 169/1000 [09:37<46:48,  3.38s/it]Epoch=170, LR=0.000058, Loss=21.0897, Val MAE=12.8041
 18%|█████████████████▏                                                                              | 179/1000 [10:14<55:11,  4.03s/it]Epoch=180, LR=0.000037, Loss=21.8314, Val MAE=13.4103
 19%|██████████████████▏                                                                             | 189/1000 [10:53<47:00,  3.48s/it]Epoch=190, LR=0.000030, Loss=21.8213, Val MAE=13.0918
 20%|███████████████████                                                                             | 199/1000 [11:29<46:42,  3.50s/it]Epoch=200, LR=0.000019, Loss=21.4293, Val MAE=12.8152
 21%|████████████████████                                                                            | 209/1000 [12:05<46:09,  3.50s/it]Epoch=210, LR=0.000012, Loss=20.4266, Val MAE=12.8936
 21%|████████████████████▌                                                                           | 214/1000 [12:26<45:42,  3.49s/it]
[Fold] Best test MAE = 13.8096